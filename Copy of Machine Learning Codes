{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uyjeuBIghdJyeIzI0gLP04J1av4cZV9q","timestamp":1671590593342},{"file_id":"1cWBgc-qtOiEup21n6X1im5kBfp2XtGAC","timestamp":1671537812107}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Linear Regression"],"metadata":{"id":"nl49W4-lLwWW"}},{"cell_type":"code","source":["# Multiple Linear Regression\n","\n","# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n","# Importing the dataset\n","url = 'https://gist.githubusercontent.com/GaneshSparkz/b5662effbdae8746f7f7d8ed70c42b2d/raw/faf8b1a0d58e251f48a647d3881e7a960c3f0925/50_Startups.csv'\n","dataset = pd.read_csv(url)\n","X = dataset.iloc[:, :-1]\n","y = dataset.iloc[:, 4]\n","\n","#Convert the column into categorical columns\n","\n","states=pd.get_dummies(X['State'],drop_first=True)\n","\n","# Drop the state coulmn\n","X=X.drop('State',axis=1)\n","\n","# concat the dummy variables\n","X=pd.concat([X,states],axis=1)\n","\n","\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n","\n","# Fitting Multiple Linear Regression to the Training set\n","from sklearn.linear_model import LinearRegression\n","regressor = LinearRegression()\n","regressor.fit(X_train, y_train)\n","\n","# Predicting the Test set results\n","y_pred = regressor.predict(X_test)\n","\n","from sklearn.metrics import r2_score\n","score=r2_score(y_test,y_pred)\n","\n","print(\"R2 Score: \", score)"],"metadata":{"id":"u70RRUiSLvMg","executionInfo":{"status":"ok","timestamp":1671557678292,"user_tz":-330,"elapsed":456,"user":{"displayName":"Chahat Nagar","userId":"09700324727839570907"}},"outputId":"0b6cac98-cc16-4345-96ed-35415dc714d2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    Florida  New York\n","0         0         1\n","1         0         0\n","2         1         0\n","3         0         1\n","4         1         0\n","5         0         1\n","6         0         0\n","7         1         0\n","8         0         1\n","9         0         0\n","10        1         0\n","11        0         0\n","12        1         0\n","13        0         0\n","14        1         0\n","15        0         1\n","16        0         0\n","17        0         1\n","18        1         0\n","19        0         1\n","20        0         0\n","21        0         1\n","22        1         0\n","23        1         0\n","24        0         1\n","25        0         0\n","26        1         0\n","27        0         1\n","28        1         0\n","29        0         1\n","30        1         0\n","31        0         1\n","32        0         0\n","33        1         0\n","34        0         0\n","35        0         1\n","36        1         0\n","37        0         0\n","38        0         1\n","39        0         0\n","40        0         0\n","41        1         0\n","42        0         0\n","43        0         1\n","44        0         0\n","45        0         1\n","46        1         0\n","47        0         0\n","48        0         1\n","49        0         0\n"]}]},{"cell_type":"markdown","source":["#Decision Tree"],"metadata":{"id":"TFUQdWa3T8_e"}},{"cell_type":"code","source":["# Run this program on your local python\n","# interpreter, provided you have installed\n","# the required libraries.\n","\n","# Importing the required packages\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","\n","# Function importing Dataset\n","def importdata():\n","\tbalance_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', sep= ',', header = None)\n","\t\n","\t# Printing the dataswet shape\n","\tprint (\"Dataset Length: \", len(balance_data))\n","\tprint (\"Dataset Shape: \", balance_data.shape)\n","\t\n","\t# Printing the dataset obseravtions\n","\tprint (\"Dataset: \",balance_data.head())\n","\treturn balance_data\n","\n","# Function to split the dataset\n","def splitdataset(balance_data):\n","\n","\t# Separating the target variable\n","\tX = balance_data.values[:, 1:5]\n","\tY = balance_data.values[:, 0]\n","\n","\t# Splitting the dataset into train and test\n","\tX_train, X_test, y_train, y_test = train_test_split(\n","\tX, Y, test_size = 0.3, random_state = 100)\n","\t\n","\treturn X, Y, X_train, X_test, y_train, y_test\n","\t\n","# Function to perform training with giniIndex.\n","def train_using_gini(X_train, X_test, y_train):\n","\n","\t# Creating the classifier object\n","\tclf_gini = DecisionTreeClassifier(criterion = \"gini\",\n","\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5)\n","\n","\t# Performing training\n","\tclf_gini.fit(X_train, y_train)\n","\treturn clf_gini\n","\t\n","# Function to perform training with entropy.\n","def tarin_using_entropy(X_train, X_test, y_train):\n","\n","\t# Decision tree with entropy\n","\tclf_entropy = DecisionTreeClassifier(\n","\t\t\tcriterion = \"entropy\", random_state = 100,\n","\t\t\tmax_depth = 3, min_samples_leaf = 5)\n","\n","\t# Performing training\n","\tclf_entropy.fit(X_train, y_train)\n","\treturn clf_entropy\n","\n","\n","# Function to make predictions\n","def prediction(X_test, clf_object):\n","\n","\t# Predicton on test with giniIndex\n","\ty_pred = clf_object.predict(X_test)\n","\tprint(\"Predicted values:\")\n","\tprint(y_pred)\n","\treturn y_pred\n","\t\n","# Function to calculate accuracy\n","def cal_accuracy(y_test, y_pred):\n","\t\n","\tprint(\"Confusion Matrix: \",\n","\t\tconfusion_matrix(y_test, y_pred))\n","\t\n","\tprint (\"Accuracy : \",\n","\taccuracy_score(y_test,y_pred)*100)\n","\t\n","\tprint(\"Report : \",\n","\tclassification_report(y_test, y_pred))\n","\n","# Driver code\n","def main():\n","\t\n","\t# Building Phase\n","\tdata = importdata()\n","\tX, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n","\tclf_gini = train_using_gini(X_train, X_test, y_train)\n","\tclf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n","\t\n","\t# Operational Phase\n","\tprint(\"Results Using Gini Index:\")\n","\t\n","\t# Prediction using gini\n","\ty_pred_gini = prediction(X_test, clf_gini)\n","\tcal_accuracy(y_test, y_pred_gini)\n","\t\n","\tprint(\"Results Using Entropy:\")\n","\t# Prediction using entropy\n","\ty_pred_entropy = prediction(X_test, clf_entropy)\n","\tcal_accuracy(y_test, y_pred_entropy)\n","\t\n","\t\n","# Calling main function\n","if __name__==\"__main__\":\n","\tmain()\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","\n","balance_data = pd.read_csv(\n","'https://archive.ics.uci.edu/ml/machine-learning-'+\n","'databases/balance-scale/balance-scale.data',\n","\tsep= ',', header = None)\n","\t\n","\t# Printing the dataswet shape\n","print (\"Dataset Length: \", len(balance_data))\n","print (\"Dataset Shape: \", balance_data.shape)\n","\n","# Printing the dataset obseravtions\n","print (\"Dataset: \",balance_data.head())\n","\n","X = balance_data.values[:, 1:5]\n","Y = balance_data.values[:, 0]\n","\n","# Splitting the dataset into train and test\n","X_train, X_test, y_train, y_test = train_test_split(\n","X, Y, test_size = 0.3, random_state = 100)\n","\n","clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n","    random_state = 100,max_depth=3, min_samples_leaf=5)\n","\n","# Performing training\n","clf_gini.fit(X_train, y_train)\n","\n","clf_entropy = DecisionTreeClassifier(\n","    criterion = \"entropy\", random_state = 100,\n","    max_depth = 3, min_samples_leaf = 5)\n","\n","# Performing training\n","clf_entropy.fit(X_train, y_train)\n","\n","#Prediction using gini\n","y_pred = clf_gini.predict(X_test)\n","print(\"Predicted values:\")\n","print(y_pred)\n","print(\"Confusion Matrix: \",\n","\n","confusion_matrix(y_test, y_pred))\n","\n","print (\"Accuracy : \",\n","accuracy_score(y_test,y_pred)*100)\n","\n","print(\"Report : \",\n","classification_report(y_test, y_pred))"],"metadata":{"id":"WvTQyRlyT-2W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#PCA"],"metadata":{"id":"fa6B-nuyWeGB"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","# load dataset into Pandas DataFrame\n","df = pd.read_csv(url, names=['sepal length','sepal width','petal length','petal width','target'])\n","\n","\n","features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n","# Separating out the features\n","x = df.loc[:, features].values\n","# Separating out the target\n","y = df.loc[:,['target']].values\n","# Standardizing the features\n","x = StandardScaler().fit_transform(x)\n","\n","\n","pca = PCA(n_components=2)\n","principalComponents = pca.fit_transform(x)\n","principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n","\n","finalDf = pd.concat([principalDf, df[['target']]], axis = 1)\n","\n","fig = plt.figure(figsize = (8,8))\n","ax = fig.add_subplot(1,1,1) \n","ax.set_xlabel('Principal Component 1', fontsize = 15)\n","ax.set_ylabel('Principal Component 2', fontsize = 15)\n","ax.set_title('2 component PCA', fontsize = 20)\n","targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n","colors = ['r', 'g', 'b']\n","for target, color in zip(targets,colors):\n","    indicesToKeep = finalDf['target'] == target\n","    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'] , finalDf.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n","ax.legend(targets)\n","ax.grid()\n","\n","pca.explained_variance_ratio_\n"],"metadata":{"id":"yd7TICAlWfok"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#SVM"],"metadata":{"id":"qwfi41MMWmrS"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","URL = 'https://raw.githubusercontent.com/aviralb13/codes/main/datas/iris.csv'\n","data = pd.read_csv(URL)\n","data.head()\n","\n","features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n","\n","x = data[features]\n","y = data['species']\n","\n","from sklearn.model_selection import train_test_split\n","\n","train_x, test_x, train_y, test_y = train_test_split(x,y)\n","\n","from sklearn.svm import SVC\n","\n","model = SVC()\n","\n","model.fit(train_x, train_y)\n","\n","prediction = model.predict(test_x)\n","\n","from sklearn.metrics import accuracy_score\n","accuracy_score(test_y, prediction)"],"metadata":{"id":"m2526EYOWowo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671555268239,"user_tz":-330,"elapsed":2065,"user":{"displayName":"Chahat Nagar","userId":"09700324727839570907"}},"outputId":"71a0f6f5-2d35-4372-96f3-b993a6472d5c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[],"metadata":{"id":"k-TywyvE2Ois"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"prakhar edited this\")"],"metadata":{"id":"5oqcEJKodQhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671578595166,"user_tz":-330,"elapsed":428,"user":{"displayName":"Prakhar mehta","userId":"14887097707734577767"}},"outputId":"a01a67e8-7964-463b-d67e-175494e767e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["prakhar edited this\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IHgxxGMT2AQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ensemble learning"],"metadata":{"id":"mgbpZXQuq6oQ"}},{"cell_type":"code","source":["# Load Library\n","from sklearn.datasets import make_moons\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n","\n","# Step1: Create data set\n","X, y = make_moons(n_samples=10000, noise=.5, random_state=0)\n","\n","# Step2: Split the training test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 3: Fit a Decision Tree model as comparison\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","accuracy_score(y_test, y_pred)\n","\n","#OUTPUT: 0.756\n","\n","# Step 4: Fit a Random Forest model, \" compared to \"Decision Tree model, accuracy go up by 5%\n","clf = RandomForestClassifier(n_estimators=100, max_features=\"auto\",random_state=0)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","accuracy_score(y_test, y_pred)\n","#OUTPUT: 0.797\n","\n","# Step 5: Fit a AdaBoost model, \" compared to \"Decision Tree model, accuracy go up by 10%\n","clf = AdaBoostClassifier(n_estimators=100)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","accuracy_score(y_test, y_pred)\n","#OUTPUT:0.833\n","\n","# Step 6: Fit a Gradient Boosting model, \" compared to \"Decision Tree model, accuracy go up by 10%\n","clf = GradientBoostingClassifier(n_estimators=100)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","accuracy_score(y_test, y_pred)\n","#OUTPUT:0.834\n","#Note: Parameter - n_estimators stands for how many tree we want to grow\n","\n"],"metadata":{"id":"R0U078XprEoe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"QWB7HlOLq9mz"}},{"cell_type":"markdown","source":["# numpy, if-else, for"],"metadata":{"id":"bgLwEv-6rQlN"}},{"cell_type":"code","source":["num = int(input(\"enter the number?\"))  \n","if num%2 == 0:  \n","    print(\"Number is even\")  \n","else:  \n","    print(\"Number is odd\")  "],"metadata":{"id":"zuS89v9crhMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random \n","numbers = [ ]  \n","for val in range(0, 11):  \n","    numbers.append( random.randint( 0, 11 ) )  \n","for num in range( 0, 11 ):  \n","    for i in numbers:  \n","        if num == i:  \n","            print( num, end = \" \" )  "],"metadata":{"id":"EhwaS43RrnO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Python program to illustrate\n","# Iterating over a list\n","print(\"List Iteration\")\n","l = [\"geeks\", \"for\", \"geeks\"]\n","for i in l:\n","\tprint(i)\n","\n","# Iterating over a tuple (immutable)\n","print(\"\\nTuple Iteration\")\n","t = (\"geeks\", \"for\", \"geeks\")\n","for i in t:\n","\tprint(i)\n","\n","# Iterating over a String\n","print(\"\\nString Iteration\")\n","s = \"Geeks\"\n","for i in s:\n","\tprint(i)\n","\n","# Iterating over dictionary\n","print(\"\\nDictionary Iteration\")\n","d = dict()\n","d['xyz'] = 123\n","d['abc'] = 345\n","for i in d:\n","\tprint(\"%s %d\" % (i, d[i]))\n","\n","# Iterating over a set\n","print(\"\\nSet Iteration\")\n","set1 = {1, 2, 3, 4, 5, 6}\n","for i in set1:\n","\tprint(i),\n","\n"],"metadata":{"id":"n3Bq9N5Hrpsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Student:\n","  def __init__(self,name,cls,roll_no):\n","    self.name=name\n","    self.classs=cls\n","    self.roll=roll_no\n","\n","    def print_info(self):\n","      return f'''Name of student - {self.name} class of student - {self.classs} roll number of the student - {self.roll}''' \n","\n","      s1 = Student('chaman','CS',08)\n","      print(s1.print_info())"],"metadata":{"id":"lg1wKrN6rvqa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Person:\n","\n","\tdef __init__(self, name):\n","\t\tself.name = name\n","\n","\tdef say_hi(self):\n","\t\tprint('Hello, my name is', self.name)\n","\n","\n","p = Person('chaman')\n","p.say_hi()\n","\n"],"metadata":{"id":"szbLu3h-rwz9"},"execution_count":null,"outputs":[]}]}